#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Code generator for evaluating the partial derivatives of the potential ϕ.

stage2.py takes in the code generated by stage1. It analyzes the dependencies
between the functions, and generates wrapper functions, where all bound symbols
(quantities defined by any of the stage1 generated functions) are automatically
computed, by calling the standalone pieces generated in stage1 (recursing
where necessary).

Each function generated by stage2 takes in values only for the free symbols
(quantities *not* defined by any of the stage1 generated functions)
encountered anywhere in its call tree. This makes e.g. ∂²ϕ/∂Bx² "see" the
dependencies on e.g. u0, I4, and εxx.

Note that "free symbol" is here meant in the mathematical sense; in the
programming sense, these "free symbols" appear in the argument list
of the function being generated, so they are bound names.

(Of course, in the programming sense, no free names can remain inside the
generated Fortran functions, or the result would not compile.)

Created on Tue Oct 24 14:07:45 2017

@author: jje
"""

import re

from iterutil import uniqify
from util import fold_fortran_code, TextMultiBuffer

##############################################################################
# Local definitions
##############################################################################

_fileheader = \
"""!******************************************************************************
!*              Code generated with mgs-galfenol-codegen stage2               *
!*                                                                            *
!*                 This file is part of 'elmer-mgs-galfenol'                  *
!******************************************************************************
"""

##############################################################################
# stage2 code generator
##############################################################################

class CodeGenerator:
    """Generate stage2 code (public API) for the stage1 code (internal functions)."""

    # no constructor, we have just static and class methods

    @staticmethod
    def analyze_interface(code):
        """Extract function call dependencies from a Fortran interface.

        This is very simplistic, and likely specific to code generated
        by SymPy's code generator.

        All functions in the interface are assumed PURE (no side effects),
        regardless of whether or not this is explicitly declared.

        Parameters:
            code: str
                Content of a Fortran interface (".h" file), as a single string.

        Return value: list of tuples (funcs, lookup), where
            funcs: tuple of tuples
                Each item has the format (fname, infargs, fargs),
                where
                    fname: str
                        Function name.
                    infargs: tuple
                        (arg1, arg2, ..., argn), intent(in) args only;
                    fargs: tuple
                        (arg1, arg2, ..., argm), all args.
                Ordering of the args is preserved.

            lookup: dictionary
                lookup[fname] = (arg1, arg2, ..., argn)  (intent(in) args only)
                This is provided for convenience.

            The top-level list has two elements; the first contains the data
            for functions, the second for subroutines.
"""
        # HACK: parse by regex matching. (Use a proper Fortran parser?)
        #
        from enum import Enum
        class ReaderState(Enum):
            SCANNING  = 0
            CAPTURING_ARGLIST = 1
            CAPTURING_INTENTS = 2

        results = {}
        for ftype in ("function", "subroutine"):
            def header_ends(line):
                endparen = re.findall(r"\)", line)
                return (len(endparen) > 0)

            def intents_end(line):  # "end function" or "end subroutine"
                end = re.findall(r"\bend %s\b" % (ftype), line)
                return (len(end) > 0)

            def commit(fname, inargs, outargs, allargs):
                if ftype == 'function' and set(inargs) != set(allargs):
                    invalid_args = sorted(set(allargs).difference(set(inargs)), key=str.lower)
                    raise ValueError("A Fortran 90 function can only have intent(in) arguments, but function '%s' has declared the following as intent(out) or intent(inout) (in alphabetical order): %s" % (fname, invalid_args))
                result.append( (fname, inargs, outargs, allargs) )

            result = []
            state = ReaderState.SCANNING
            for line in code.split("\n"):
                if state == ReaderState.SCANNING:
                    # match "function" but not "end function" (see "help re")
                    # (and similarly for subroutines)
                    m = re.findall(r"(?<!\bend\b)\s+\b%s\b"% (ftype), line)

                    if len(m):  # if found, start capturing
                        # - skip keyword "function" and whitespace
                        # - capture function name (non-whitespace, 1 or more)
                        # - then skip "("
                        # - finally capture arguments:
                        #     - up to end of line, 0 or more of anything that is not "&" or ")"
                        #     - *0* or more because some functions might not take any arguments!
                        matches = re.findall(r"\b%s\b\s+(\S+)\(([^&)]*)" % (ftype), line)
                        assert len(matches) == 1  # should be just one match for the whole regex
                        groups = matches[0]

                        fname = groups[0]
                        allargs = groups[1].strip().split(",")
                        allargs = [s.strip() for s in allargs if len(s.strip())]
                        outargs = []  # for collecting intent(out) args in CAPTURING_INTENTS state

                        # Before we change state, we must check whether the whole
                        # function header was on this line.
                        #
                        # If not, capture the rest of fargs from the following
                        # lines. Else move on to capturing intents.
                        #
                        if not header_ends(line):
                            state = ReaderState.CAPTURING_ARGLIST
                        else:
                            state = ReaderState.CAPTURING_INTENTS

                elif state == ReaderState.CAPTURING_ARGLIST:
                    # capture function arguments from this line
                    groups = re.findall(r"[^&)]+", line)  # one group only, no wrapper
                    moreargs = groups[0].strip().split(",")
                    moreargs = [s.strip() for s in moreargs if len(s.strip())]
                    allargs.extend(moreargs)

                    # If these were the last fargs, move on to capturing intents.
                    if header_ends(line):
                        state = ReaderState.CAPTURING_INTENTS

                # Parse args also from decls, to ignore any args with intent(out).
                # This is needed to support subroutines with output args.
                elif state == ReaderState.CAPTURING_INTENTS:
                    matches = re.findall(r"intent\((\w+)\) :: (.*)", line)
                    if len(matches):
                        assert len(matches) == 1
                        groups = matches[0]

                        intent = groups[0]
                        arg    = groups[1]

                        if intent not in ("in", "out", "inout"):
                            raise ValueError("While processing declaration of '%s': invalid intent '%s' for arg '%s'; valid: 'in', 'out' or 'inout'" % (fname, intent, arg))

                        if intent == "out":
                            outargs.append(arg)
                    # else no decl with intent on this line

                    if intents_end(line):
                        # Separate input and output args when committing.
                        #
                        # We capture three lists:
                        #  - input args only, so that we can compute any
                        #    dependent inputs by calling other stage1
                        #    API functions (of the same name as an input arg)
                        #  - output args, to be passed through
                        #    (for the final layer of the cake,
                        #     which may have subroutines)
                        #  - all args in original order, to write the call
                        #    to the stage1 API function when writing the
                        #    stage2 public API
                        #
                        # TODO: The code generator is a bit simplistic
                        # in that we do not support using output args to
                        # generate dependent inputs, but this is sufficient
                        # for the pure-function interfaces generated by SymPy,
                        # (as well as the manually written interfaces we will
                        # feed in in this project, where any output args are
                        # intended only to be passed through, to the end user).
                        #
                        inargs = [arg for arg in allargs if arg not in outargs]
                        commit(fname, inargs, outargs, allargs)
                        state = ReaderState.SCANNING

                else:
                    assert False, "Unknown reader state"

            results[ftype] = result

        # When we finish, the reader should be in the SCANNING state,
        # as always after a complete function declaration.
        #
        if state != ReaderState.SCANNING:
            raise ValueError("End of file while processing declaration of '%s'" % (fname))

        # Validate: no subroutine names must appear in (intent(in)) args of any function.
        #
        # We only support subroutines in the final layer of the "cake",
        # where the intent(out) args go to the user.
        #
        subroutine_names = {name for name,_,_,_ in results["subroutine"]}
        for name,inargs,_,_ in results["function"]:
            for arg in inargs:
                if arg in subroutine_names:
                    raise ValueError("Function '%s' depends on subroutine '%s'; this is currently not supported." % (name, arg))

        return [(results[key], {name:inargs for name,inargs,_,_ in results[key]}) for key in sorted(results.keys())]

    @staticmethod
    def make_analyzer(lookup):
        """Make ``analyze_args`` function that uses lookup table ``lookup``.

        (This avoids a dependency on mutable state.)
        """
        def analyze_args(args, recurse, _level=0):
            """Split args to bound and free sets.

            Any arg names that exist in ``lookup[]`` are considered to be
            bound to those functions.

            All other arguments are considered free.

            Parameters:
                args: tuple of str
                    Formal argument names of a stage1 generated function.
                    Each name is, generally:
                      a) the name of another stage1 generated function, or
                      b) a free argument (anything not defined by stage1 code).
                    See ``analyze_interface()``.

                recurse: bool
                    If True, recurse into ``args``.

                    If False, analyze only the local level.

                _level: int
                    Internal parameter that keeps track of the depth of recursion,
                    i.e. how deep in the call tree the arg is needed.

                    (Just leave this at its default value.)

            Returns:
                set of ``(level,arg)`` pairs
                    where ``level`` (int) is the recursion depth where
                    ``arg`` (str) was seen.

                    0 means top level.

                    ``i > 0`` means "needed by level ``i-1``".

                    The same arg may appear at multiple levels; in this case,
                    each level has its own instance in the results.
            """
            # Implemented using mutual recursion:
            #   - analyze_args() injects the level information into a raw args list
            #   - analyze_internal() does the rest of the work
            return analyze_internal([(_level,arg) for arg in args], recurse)
        def analyze_internal(args, recurse):
            bound = set()
            free  = set()
            for item in args:
                level,arg = item
                if arg in lookup:  # if we know a stage1 function of this name
                    bound.add((level,arg))
                    if recurse:
                        b,f = analyze_args(lookup[arg], recurse, level+1)
                        bound.update(b)
                        free.update(f)
                else:
                    free.add((level,arg))
            return (bound,free)
        return analyze_args

    @staticmethod
    def make_sortkey(primary="level", reverse_primary=False, reverse_secondary=False):
        """Sort helper for output of analyze_args().

        Parameters:
            primary: str
                "level": level first, then name as tie-breaker
                "name": name first, then level as tie-breaker

        Returns:
            lambda item: ... that can be used in ``sorted()`` as ``key``.
"""
        if primary not in ("level","name"):
            raise ValueError("Unknown primary sort criterion '%s'; valid: 'level', 'name'" % (primary))
        indx0 = 0 if primary == "level" else 1
        indx1 = 1 - indx0  # the other one
        sign0 = -1 if reverse_primary else +1
        sign1 = -1 if reverse_secondary else +1
        return lambda item: (sign0*item[indx0], sign1*item[indx1])

    @staticmethod
    def strip_levels(args):
        """Strip level information from output of analyze_args()."""
        return [arg for (_,arg) in args]

    @classmethod  # we need access to strip_levels()
    def make_validator(cls, lookup):
        """Make ``validate_bound_args`` function that uses lookup table ``lookup``.

        (This avoids a dependency on mutable state.)
        """
        def validate_bound_args(bound):
            """Validate bound args.

            If this check passes, it proves that the dependencies between the
            functions declared in the analyzed Fortran interface are NOT:

              - recursive (a function calling into itself or into any parent
                           on its call stack)
              - mutually recursive (a calling b and b calling a; this is detected
                                    even if the calls are in different call chains)

            on the condition that ``analyze_interface()`` and ``analyze_args()``
            are implemented correctly.

            (We still need to rely on other means to make sure that the stage2
            analyzer and code generator are correct.)

            Parameters:
                bound: set of ``(level,arg)`` (int, str) pairs
                    as output by ``analyze_args()`` with ``recursive=True``.

            Returns:
                None
                    ``NotImplementedError`` is raised if the validation fails
                    (as this stage2 code generator cannot currently handle
                     interfaces which do not pass this validation).
            """
            # We check the following local property: each call chain must
            # not call anything already seen in that particular call chain.
            #
            # Also, we disallow mutual recursion: if "a" is in the set of callers
            # of "b", then "b" must not be in the set of callers of "a".

            # Check top level; we should be given only bound args.
            #
            args = cls.strip_levels(bound)
            for toplevel_arg in args:
                if toplevel_arg not in lookup:
                    raise ValueError("Got free top-level arg %s; only bound args supported by this checker" % (toplevel_arg))

            # Sets of callers of each bound var, for mutual recursion detection.
            #
            # Basically the callers of "func" are the content of the call stack
            # just before we push "func" itself onto the stack. This includes
            # "implicit" callers, in the sense that f in f(g(h(x))) implicitly
            # calls h, because g does.
            #
            # (To collect only the explicit callers, we would take only the
            #  current topmost item in the call stack.)
            #
            # The sets of callers are built globally across all call chains;
            # the set of callers of "func" is updated with any new callers
            # of "func" encountered in any call chain.
            #
            callers_of = {}  # str: set
            def update_callers_of(k, more_v):
                if k not in callers_of:
                    callers_of[k] = more_v
                else:
                    callers_of[k].update(more_v)

            # Validate each chain individually.
            #
            # As a side effect, this builds the callers_of dictionary.
            #
            def process(arg, callstack):
                # - We want to track *each chain of calls* independently.
                #   (E.g. in dwp_dI6 in the 3par model, both I5 and I6,
                #    at the same level, depend on exx.)
                # - Python is call-by-sharing (call-by-object).
                # - Hence, to avoid munging caller's "callstack" object, we copy.
                # - This makes "callstack" what it says on the tin, for the
                #   current chain of calls.
                if arg in lookup:  # only validate if arg is bound (free args may occur anywhere along the chain)
                    if arg in callstack:
                        raise NotImplementedError("top-level arg %s: recursive call to %s detected (current call stack: %s)" % (toplevel_arg,arg,callstack))
                    update_callers_of(arg, set(callstack))
                    new_callstack = callstack.copy()
                    new_callstack.append(arg)
                    for a in lookup[arg]:  # recurse into the call tree
                        process(a, new_callstack)
            for toplevel_arg in args:
                process(toplevel_arg, [])

            # Detect mutual recursion between different call chains.
            #
            # TODO: improve error message?
            #   - what information do we need to store to pinpoint the location of the error?
            #   - maybe the state of the call stack at each call site?
            #
            for a in callers_of.keys():     # a = the thing being called
                for b in callers_of[a]:     # b = its callers (i.e. each b is known to call a, at least implicitly)
                    if a in callers_of[b]:  # so if a calls b (even if implicitly), there is mutual recursion
                        raise NotImplementedError("mutual recursion (possibly implicit) detected between %s and %s (callers of %s: %s; callers of %s: %s)" % (a,b,a,callers_of[a],b,callers_of[b]))
        return validate_bound_args

    @classmethod
    def run(cls, data):
        """Generate the stage2 code (i.e. the public API).

        Parameters:
            data: tuple of tuples
                Each item should have (label, filename, content).
                This is the output format of stage1.CodeGenerator.run().
        """
        # we need to analyze only the interfaces (headers, ".h")
        stage1_intf = [(l,f,c) for l,f,c in data if f.endswith(".h")]

        # Add in user-defined interfaces.
        #
        # These are just pasted to the end of the content, so that they get
        # fed into the interface analyzer along with the automatically generated
        # stage1 interfaces.
        #
        # Here the tag "{label}" is automatically replaced by "2par" or "3par"
        # as appropriate.
        #
        user_intfs = ("mgs_{label}_phi.h", "mgs_physfields.h")
        final_stage1_intf = []
        for l,f,c in stage1_intf:
            for filename in (fn.format(label=l) for fn in user_intfs):
                print("stage2: %s model: reading user stage1 API '%s'" % (l, filename))
                with open(filename, "rt", encoding="utf-8") as f:
                    content = f.read()
                c += content
            final_stage1_intf.append((l, f, c))
        stage1_intf = final_stage1_intf

        def make_sorted_by(key):
            # Return a sorter that uses key.
            #
            # A sorter is a one-argument function that takes in a data iterable
            # and returns a sorted copy, sorting by the key.
            return lambda data: sorted(data, key=key)
        sorted_by_level_dsc = make_sorted_by(cls.make_sortkey(primary="level", reverse_primary=True))

        generated_code_out = []
        key_impl = "implementation"
        key_intf = "interface"
        key_both = (key_impl, key_intf)
        for i, (label, input_filename, content) in enumerate(stage1_intf):

            progress_header_outer = "(%d/%d)" % (i+1, len(stage1_intf))
            print("stage2: %s %s model: generating public API based on '%s'" % (progress_header_outer, label, input_filename))

            # Text of implementation and interface will be added into named
            # buffers. This is convenient because they are mostly identical.
            #
            output = TextMultiBuffer()

            # Parse dependencies between the stage1 generated functions.
            #
            data_funcs,data_subroutines = cls.analyze_interface(content)
            funcs,lookup_inargs = data_funcs  # lookup[fname] --> intent(in) args
            analyze_args = cls.make_analyzer(lookup_inargs)
            validate_bound_args = cls.make_validator(lookup_inargs)

            # TODO: use data_subroutines
            #
            #     - intent(out) args: copy to args of the public API function,
            #       with the same name. Tag as intent(out). In the generated
            #       code, pass through to the implementation.
            #       - Can use the allargs list captured by analyze_interface()
            #         to write the arguments in the correct position.
            #         Map it by the localvar logic, as usual; this replaces
            #         only intent(in) args.

            # To write the wrapper for a function f, we need:
            #
            #  - Free symbols (in the mathematical sense):
            #      - Must be supplied by caller; add to arg list of wrapper
            #  - Bound symbols:
            #      - Call the corresponding stage1 generated functions in the
            #        body of the wrapper, then use the obtained values.
            #      - If we do this in reverse order of call tree depth
            #        of the deepest instance seen of each bound arg,
            #        we already have available any bound inputs for that call.
            #      - This follows from the facts that:
            #          1) No recursion or mutual recursion in the call tree
            #             (as checked by validate_bound_args())
            #          2) The "leaf" calls in the call tree only depend
            #             on free args (at most)
            #          3) The stage1 generated code consists of pure functions;
            #             each computed value, even if needed several times
            #             during the computation of our output, is always the
            #             same (for the same values of the free vars).
            #
            # We must do this recursively; for variables needed directly by f,
            # and for variables needed by something f calls.
            #
            for j, (stage1_fname, stage1_inargs, stage1_outargs, stage1_allargs) in enumerate(funcs):

                progress_header_inner = "(%d/%d)" % (j+1, len(funcs))
                progress_header = "%s %s" % (progress_header_outer, progress_header_inner)
                print("stage2: %s %s model: public API for %s" % (progress_header, label, stage1_fname))

                # Check which intent(in) args of fname match stage1 functions.
                # This gives us bound and free argument sets for fname.
                #
                bound_set,free_set = analyze_args(stage1_inargs, recurse=True)

                # Check that the declared interface doesn't try to do
                # anything silly that is not supported by this stage2
                # code generator.
                #
                # (concerning dependencies between the bound variables,
                #  which are defined by the stage1 generated functions)
                #
                validate_bound_args(bound_set)

                # Args corresponding to free variables do not have a particular
                # ordering in the API of fname itself, as they are generally
                # propagated from the deeper levels of the call tree
                # (i.e. needed by something that fname itself calls).
                # Just order them lexicographically.
                #
                # Args corresponding to bound variables must be ordered
                # by level, decreasing, as noted above.
                #
                freevars  = sorted(uniqify(cls.strip_levels(free_set)))
                boundvars = tuple(uniqify(cls.strip_levels(sorted_by_level_dsc(bound_set))))
                # mapping for boundvar: localvar for temp variables
                # generated for storing values of boundvars at this call site.
                localvars = {}

                # TODO: handle also subroutines
                #   TODO of TODO: be a bit more explicit here...

                # output: function header
                #
                stage2_fname = "%s_public"% (stage1_fname)  # name of public API function to write
                output.append(key_both, "\n")  # blank line before start of item
                output.append(key_intf, "interface\n")
                output.append(key_both, "REAL*8 function %s(" % (stage2_fname))
                output.append(key_both, ", ".join(freevars))
                output.append(key_both, ")\n")

                # output: argument declarations for the public API function (free variables only!)
                output.append(key_both, "implicit none\n")
                for var in freevars:
                    output.append(key_both, "REAL*8, intent(in) :: %s\n" % (var))

                # Declare any needed localvars and populate them by calls to
                # the stage1 functions represented by boundvars.

                # bind bound variables in given inargs to corresponding
                # local variables (if any), preserving ordering.
                # Any free variables in inargs are passed through as-is.
                def bind_to_lvars(inargs):
                    result = [(localvars[arg] if arg in boundvars else arg) for arg in inargs]
                    # sanity check: each bound var in myargs should now be bound,
                    # so the result should have only localvars or freevars
                    for arg in result:
                        # localvars.keys()   = the names of the *bound* vars
                        # localvars.values() = the names of the *local* vars
                        if arg in localvars.values() or arg in freevars:
                            continue
                        raise RuntimeError("post-binding check: undefined symbol '%s', neither in localvars nor in freevars" % (arg))
                    return result

                # We need a temp storage buffer: we must first process all
                # boundvars to generate all of localvars, but in the output,
                # we must write the declarations of all localvars first,
                # before writing the calls to the boundvar functions
                # (that then populate the localvars).
                tmpbuffer = ""
                for bvar in boundvars:  # follow the ordering by level, descending (deepest first)
                    lvar = "%s_" % (bvar)
                    # output: call the stage1 function for this boundvar.
                    #
                    # At each iteration, when writing the function call,
                    # we bind to localvars any arguments that already
                    # have a corresponding localvar.
                    #
                    # The descending level ordering makes sure that the each
                    # call generated here will, in its arguments, contain
                    # only vars that already have a localvar, or free vars
                    # (which are supplied in the stage2 argument list).
                    # Thus, in each call, no unbound vars remain.
                    #
                    # TODO later: if no function name matches an input arg,
                    # we could check if there is a subroutine that provides
                    # it as one of its output args, and call it.
                    #
                    # Note that in any argument lists for *calls to* functions
                    # representing the bound variables, we must use data
                    # from lookup_inargs[] (or funcs), because it preserves
                    # the original ordering of args (which are positional
                    # in Fortran!).
                    tmpbuffer += "%s = %s(%s)\n" % (lvar, bvar, ", ".join(bind_to_lvars(lookup_inargs[bvar])))
                    localvars[bvar] = lvar
                # end bound vars init section (if any needed) with blank line
                if len(boundvars):
                    tmpbuffer += "\n"

                # output: declare localvars
                for bvar in boundvars:  # use same ordering as boundvars, for readability
                    output.append(key_impl, "REAL*8 %s\n" % (localvars[bvar]))

                # end argument and local variable declarations with blank line
                # (there is always at least the "implicit none"; if there wasn't,
                #  we would have to check the combined length of freevars and
                #  localvars)
                output.append(key_impl, "\n")

                # output: evaluate localvars
                output.append(key_impl, tmpbuffer)

                # output: call the stage1 function stage1_fname itself.
                #
                # Bind any arguments that have a localvar.
                # Now all boundvars do - any remaining ones are freevars.
                output.append(key_impl, "%s = %s(%s)\n" % (stage2_fname, stage1_fname, ", ".join(bind_to_lvars(stage1_inargs))))

                output.append(key_impl, "\n")  # end function body with blank line
                output.append(key_both, "end function\n")
                output.append(key_intf, "end interface\n")

            # Generate the final code for the output files
            #
            outfile_basename = "mgs_%s" % (label)
            outfile_implname = "%s.f90" % (outfile_basename)
            outfile_intfname = "%s.h"   % (outfile_basename)

            output_impl = _fileheader + fold_fortran_code(output[key_impl])
            output_intf = _fileheader + fold_fortran_code(output[key_intf])

            generated_code_out.append((label, outfile_implname, output_impl))
            generated_code_out.append((label, outfile_intfname, output_intf))

        return generated_code_out

##############################################################################
# Main program (stage2 only)
##############################################################################

def load_stage1_files():
    """Load stage1 data from disk and return list of tuples (label,filename,content)."""
    def relevant(filename):
        return len(re.findall(r"[23]par_impl.*\.(f90|h)", filename))
    def npar(filename):
        groups = re.findall(r"(\d+par)", filename)  # 2par, 3par
        return groups[0]
    import os
    path = "."
    just_files = [x for x in os.listdir(path) if os.path.isfile(os.path.join(path, x))]
    matching_files = [x for x in just_files if relevant(x)]
    if not len(matching_files):
        raise(ValueError("No stage1 files found; please generate them first by running stage1.py."))
    s1code = []
    for filename in matching_files:
        label = npar(filename)
        with open(filename, "rt", encoding="utf-8") as f:
            content = f.read()
        s1code.append((label,filename,content))
    return s1code

def main():
#    # we could call stage1, like this:
#    import stage1
#    s1code = stage1.CodeGenerator.run()

    # But we can just load stage1 files to be able to run s2 standalone.
    s1code = load_stage1_files()

    s2code = CodeGenerator.run(s1code)  # stage2 CodeGenerator

    for label, filename, content in s2code:
        print("stage2: writing %s for %s" % (filename, label))
        with open(filename, "wt", encoding="utf-8") as f:
            f.write(content)

if __name__ == '__main__':
    main()
